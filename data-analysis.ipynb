{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import tree_grow, tree_grow_b, tree_pred, tree_pred_b\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"eclipse-metrics-packages-2.0.csv\", delimiter=\";\")\n",
    "test = pd.read_csv(\"eclipse-metrics-packages-3.0.csv\", delimiter=\";\")\n",
    "list(train.columns[4:44])\n",
    "feats = ['pre',\n",
    " 'ACD_avg',\n",
    " 'ACD_max',\n",
    " 'ACD_sum',\n",
    " 'FOUT_avg',\n",
    " 'FOUT_max',\n",
    " 'FOUT_sum',\n",
    " 'MLOC_avg',\n",
    " 'MLOC_max',\n",
    " 'MLOC_sum',\n",
    " 'NBD_avg',\n",
    " 'NBD_max',\n",
    " 'NBD_sum',\n",
    " 'NOCU',\n",
    " 'NOF_avg',\n",
    " 'NOF_max',\n",
    " 'NOF_sum',\n",
    " 'NOI_avg',\n",
    " 'NOI_max',\n",
    " 'NOI_sum',\n",
    " 'NOM_avg',\n",
    " 'NOM_max',\n",
    " 'NOM_sum',\n",
    " 'NOT_avg',\n",
    " 'NOT_max',\n",
    " 'NOT_sum',\n",
    " 'NSF_avg',\n",
    " 'NSF_max',\n",
    " 'NSF_sum',\n",
    " 'NSM_avg',\n",
    " 'NSM_max',\n",
    " 'NSM_sum',\n",
    " 'PAR_avg',\n",
    " 'PAR_max',\n",
    " 'PAR_sum',\n",
    " 'TLOC_avg',\n",
    " 'TLOC_max',\n",
    " 'TLOC_sum',\n",
    " 'VG_avg',\n",
    " 'VG_max',\n",
    " 'VG_sum']\n",
    "train_x = train[feats]\n",
    "train_y = train[\"post\"]\n",
    "test_x = test[feats]\n",
    "test_y = test[\"post\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np = train_x.to_numpy()\n",
    "test_x_np = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_np = train_y.to_numpy()\n",
    "train_y_np = np.where(train_y_np > 0, 1, 0)\n",
    "test_y_np = test_y.to_numpy()\n",
    "test_y_np = np.where(test_y_np > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree = tree_grow(train_x_np, train_y_np, 15, 5, 41)\n",
    "test_y_np_pred_st = tree_pred(test_x_np, single_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(single_tree.y) == (len(single_tree.l.y) + len(single_tree.r.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_scores(y_true,y_pred):\n",
    "    conf_mat = confusion_matrix(y_true,y_pred)\n",
    "    tn = conf_mat[0][0]\n",
    "    fp = conf_mat[0][1]\n",
    "    fn = conf_mat[1][0]\n",
    "    tp = conf_mat[1][1]\n",
    "    print(\"Confusion matrix:\")\n",
    "    display(Markdown(f'''| True/Pred |Pos|Neg|\n",
    "|-----------|---|---|\n",
    "|       Pos |{tp}|{fn}|\n",
    "|       Neg |{fp}|{tn}|\n",
    "    '''))\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"LaTex formatting:\", '''\n",
    "\\\\begin{table}[]\n",
    "\\\\begin{tabular}{|r|l|l|}\n",
    "\\\\hline\n",
    "True/Pred & Pos & Neg \\\\\\ \\hline''')\n",
    "    print(f\"Pos                             &  {tp}   &  {fn}   \\\\\\ \\hline\")\n",
    "    print(f\"Neg                             & {fp}    &  {tn}   \\\\\\ \\hline\")\n",
    "    print('''\\end{tabular}\n",
    "\\end{table}''')\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"accuracy:\", accuracy_score(y_true,y_pred))\n",
    "    print(\"precision:\", precision_score(y_true,y_pred))\n",
    "    print(\"recall:\", recall_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| True/Pred |Pos|Neg|\n",
       "|-----------|---|---|\n",
       "|       Pos |184|79|\n",
       "|       Neg |129|269|\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LaTex formatting: \n",
      "\\begin{table}[]\n",
      "\\begin{tabular}{|r|l|l|}\n",
      "\\hline\n",
      "True/Pred & Pos & Neg \\\\ \\hline\n",
      "Pos                             &  184   &  79   \\\\ \\hline\n",
      "Neg                             & 129    &  269   \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "------------------------------------\n",
      "accuracy: 0.6853252647503782\n",
      "precision: 0.5878594249201278\n",
      "recall: 0.6996197718631179\n"
     ]
    }
   ],
   "source": [
    "report_scores(test_y_np_pred_st, test_y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root values: split_feature = pre, split_value = 4.5, y_values_1_ratio = 0.5039787798408488\n"
     ]
    }
   ],
   "source": [
    "# Print the first two-layers of the tree\n",
    "# Root node information\n",
    "root = single_tree\n",
    "split_feature = feats[root.f]\n",
    "split_value = root.s\n",
    "y_values = root.y\n",
    "y_values_1_ratio = sum(y_values)/len(y_values)\n",
    "print(f\"Root values: split_feature = {split_feature}, split_value = {split_value}, y_values_1_ratio = {y_values_1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187 190]\n",
      "4.5\n",
      "pre\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.y))\n",
    "# print(single_tree.f)\n",
    "print(single_tree.s)\n",
    "print(feats[single_tree.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156  58]\n",
      "26.5\n",
      "VG_max\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.l.y))\n",
    "print(single_tree.l.s)\n",
    "print(feats[single_tree.l.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31 132]\n",
      "0.1583333333333333\n",
      "NOI_avg\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.r.y))\n",
    "print(single_tree.r.s)\n",
    "print(feats[single_tree.r.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_tree = tree_grow_b(train_x_np, train_y_np, 15, 5, 41, 100)\n",
    "test_y_np_pred_bt = tree_pred_b(test_x_np, bagging_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| True/Pred |Pos|Neg|\n",
       "|-----------|---|---|\n",
       "|       Pos |212|42|\n",
       "|       Neg |101|306|\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LaTex formatting: \n",
      "\\begin{table}[]\n",
      "\\begin{tabular}{|r|l|l|}\n",
      "\\hline\n",
      "True/Pred & Pos & Neg \\\\ \\hline\n",
      "Pos                             &  212   &  42   \\\\ \\hline\n",
      "Neg                             & 101    &  306   \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "------------------------------------\n",
      "accuracy: 0.783661119515885\n",
      "precision: 0.6773162939297125\n",
      "recall: 0.8346456692913385\n"
     ]
    }
   ],
   "source": [
    "report_scores(test_y_np_pred_bt, test_y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tree = tree_grow_b(train_x_np, train_y_np, 15, 5, 6, 100)\n",
    "test_y_np_pred_rt = tree_pred_b(test_x_np, random_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| True/Pred |Pos|Neg|\n",
       "|-----------|---|---|\n",
       "|       Pos |219|61|\n",
       "|       Neg |94|287|\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LaTex formatting: \n",
      "\\begin{table}[]\n",
      "\\begin{tabular}{|r|l|l|}\n",
      "\\hline\n",
      "True/Pred & Pos & Neg \\\\ \\hline\n",
      "Pos                             &  219   &  61   \\\\ \\hline\n",
      "Neg                             & 94    &  287   \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "------------------------------------\n",
      "accuracy: 0.7655068078668684\n",
      "precision: 0.6996805111821086\n",
      "recall: 0.7821428571428571\n"
     ]
    }
   ],
   "source": [
    "report_scores(test_y_np_pred_rt, test_y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
