{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import tree_grow, tree_grow_b, tree_pred, tree_pred_b\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from mlxtend.evaluate import mcnemar\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "from time import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"eclipse-metrics-packages-2.0.csv\", delimiter=\";\")\n",
    "test = pd.read_csv(\"eclipse-metrics-packages-3.0.csv\", delimiter=\";\")\n",
    "list(train.columns[4:44])\n",
    "feats = ['pre',\n",
    " 'ACD_avg',\n",
    " 'ACD_max',\n",
    " 'ACD_sum',\n",
    " 'FOUT_avg',\n",
    " 'FOUT_max',\n",
    " 'FOUT_sum',\n",
    " 'MLOC_avg',\n",
    " 'MLOC_max',\n",
    " 'MLOC_sum',\n",
    " 'NBD_avg',\n",
    " 'NBD_max',\n",
    " 'NBD_sum',\n",
    " 'NOCU',\n",
    " 'NOF_avg',\n",
    " 'NOF_max',\n",
    " 'NOF_sum',\n",
    " 'NOI_avg',\n",
    " 'NOI_max',\n",
    " 'NOI_sum',\n",
    " 'NOM_avg',\n",
    " 'NOM_max',\n",
    " 'NOM_sum',\n",
    " 'NOT_avg',\n",
    " 'NOT_max',\n",
    " 'NOT_sum',\n",
    " 'NSF_avg',\n",
    " 'NSF_max',\n",
    " 'NSF_sum',\n",
    " 'NSM_avg',\n",
    " 'NSM_max',\n",
    " 'NSM_sum',\n",
    " 'PAR_avg',\n",
    " 'PAR_max',\n",
    " 'PAR_sum',\n",
    " 'TLOC_avg',\n",
    " 'TLOC_max',\n",
    " 'TLOC_sum',\n",
    " 'VG_avg',\n",
    " 'VG_max',\n",
    " 'VG_sum']\n",
    "train_x = train[feats]\n",
    "train_y = train[\"post\"]\n",
    "test_x = test[feats]\n",
    "test_y = test[\"post\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>ACD_avg</th>\n",
       "      <th>ACD_max</th>\n",
       "      <th>ACD_sum</th>\n",
       "      <th>FOUT_avg</th>\n",
       "      <th>FOUT_max</th>\n",
       "      <th>FOUT_sum</th>\n",
       "      <th>MLOC_avg</th>\n",
       "      <th>MLOC_max</th>\n",
       "      <th>MLOC_sum</th>\n",
       "      <th>NBD_avg</th>\n",
       "      <th>NBD_max</th>\n",
       "      <th>NBD_sum</th>\n",
       "      <th>NOCU</th>\n",
       "      <th>NOF_avg</th>\n",
       "      <th>NOF_max</th>\n",
       "      <th>NOF_sum</th>\n",
       "      <th>NOI_avg</th>\n",
       "      <th>NOI_max</th>\n",
       "      <th>NOI_sum</th>\n",
       "      <th>NOM_avg</th>\n",
       "      <th>NOM_max</th>\n",
       "      <th>NOM_sum</th>\n",
       "      <th>NOT_avg</th>\n",
       "      <th>NOT_max</th>\n",
       "      <th>NOT_sum</th>\n",
       "      <th>NSF_avg</th>\n",
       "      <th>NSF_max</th>\n",
       "      <th>NSF_sum</th>\n",
       "      <th>NSM_avg</th>\n",
       "      <th>NSM_max</th>\n",
       "      <th>NSM_sum</th>\n",
       "      <th>PAR_avg</th>\n",
       "      <th>PAR_max</th>\n",
       "      <th>PAR_sum</th>\n",
       "      <th>TLOC_avg</th>\n",
       "      <th>TLOC_max</th>\n",
       "      <th>TLOC_sum</th>\n",
       "      <th>VG_avg</th>\n",
       "      <th>VG_max</th>\n",
       "      <th>VG_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.397878</td>\n",
       "      <td>0.487768</td>\n",
       "      <td>2.639257</td>\n",
       "      <td>7.559682</td>\n",
       "      <td>3.569337</td>\n",
       "      <td>37.143236</td>\n",
       "      <td>726.572944</td>\n",
       "      <td>6.886520</td>\n",
       "      <td>72.989390</td>\n",
       "      <td>1421.830239</td>\n",
       "      <td>1.408035</td>\n",
       "      <td>4.970822</td>\n",
       "      <td>284.503979</td>\n",
       "      <td>17.848806</td>\n",
       "      <td>2.655245</td>\n",
       "      <td>12.607427</td>\n",
       "      <td>54.798408</td>\n",
       "      <td>0.172434</td>\n",
       "      <td>0.509284</td>\n",
       "      <td>2.822281</td>\n",
       "      <td>7.919620</td>\n",
       "      <td>32.379310</td>\n",
       "      <td>177.769231</td>\n",
       "      <td>0.827946</td>\n",
       "      <td>0.978780</td>\n",
       "      <td>15.034483</td>\n",
       "      <td>2.277422</td>\n",
       "      <td>21.811671</td>\n",
       "      <td>41.076923</td>\n",
       "      <td>1.181801</td>\n",
       "      <td>12.604775</td>\n",
       "      <td>21.246684</td>\n",
       "      <td>1.020060</td>\n",
       "      <td>4.957560</td>\n",
       "      <td>210.114058</td>\n",
       "      <td>117.645997</td>\n",
       "      <td>494.687003</td>\n",
       "      <td>2113.901857</td>\n",
       "      <td>2.276089</td>\n",
       "      <td>19.809019</td>\n",
       "      <td>480.114058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.791585</td>\n",
       "      <td>0.914659</td>\n",
       "      <td>3.739858</td>\n",
       "      <td>16.867357</td>\n",
       "      <td>2.278178</td>\n",
       "      <td>36.675557</td>\n",
       "      <td>1722.374379</td>\n",
       "      <td>4.667409</td>\n",
       "      <td>90.803798</td>\n",
       "      <td>3634.398730</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>2.323950</td>\n",
       "      <td>687.157223</td>\n",
       "      <td>22.557750</td>\n",
       "      <td>3.885536</td>\n",
       "      <td>20.484679</td>\n",
       "      <td>94.776931</td>\n",
       "      <td>0.277450</td>\n",
       "      <td>0.500578</td>\n",
       "      <td>6.726633</td>\n",
       "      <td>5.384483</td>\n",
       "      <td>37.169636</td>\n",
       "      <td>443.802545</td>\n",
       "      <td>0.277751</td>\n",
       "      <td>0.177379</td>\n",
       "      <td>21.431146</td>\n",
       "      <td>6.283659</td>\n",
       "      <td>72.670226</td>\n",
       "      <td>94.109527</td>\n",
       "      <td>3.402363</td>\n",
       "      <td>51.386834</td>\n",
       "      <td>69.903088</td>\n",
       "      <td>0.439893</td>\n",
       "      <td>3.203771</td>\n",
       "      <td>455.568578</td>\n",
       "      <td>127.328041</td>\n",
       "      <td>593.967554</td>\n",
       "      <td>4824.224327</td>\n",
       "      <td>1.327293</td>\n",
       "      <td>29.697421</td>\n",
       "      <td>1343.046313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>4.405405</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.842105</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.743455</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>59.700000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>1.673913</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.521277</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>6.627737</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>1.468227</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.780488</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>97.153846</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>2.211268</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.830189</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>854.000000</td>\n",
       "      <td>8.674699</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1529.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.352941</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.173077</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>2305.000000</td>\n",
       "      <td>2.674699</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>28201.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>60190.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>11611.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>63.250000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>7669.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>1049.000000</td>\n",
       "      <td>1119.000000</td>\n",
       "      <td>56.714286</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7059.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>5207.000000</td>\n",
       "      <td>79474.000000</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>23255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pre     ACD_avg     ACD_max     ACD_sum    FOUT_avg    FOUT_max  \\\n",
       "count  377.000000  377.000000  377.000000  377.000000  377.000000  377.000000   \n",
       "mean    11.397878    0.487768    2.639257    7.559682    3.569337   37.143236   \n",
       "std     21.791585    0.914659    3.739858   16.867357    2.278178   36.675557   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000    0.000000    0.000000    0.000000    2.166667   16.000000   \n",
       "50%      3.000000    0.148148    1.000000    1.000000    3.521277   29.000000   \n",
       "75%     12.000000    0.620690    4.000000    8.000000    4.830189   45.000000   \n",
       "max    179.000000    9.000000   24.000000  150.000000   20.500000  310.000000   \n",
       "\n",
       "           FOUT_sum    MLOC_avg    MLOC_max      MLOC_sum     NBD_avg  \\\n",
       "count    377.000000  377.000000  377.000000    377.000000  377.000000   \n",
       "mean     726.572944    6.886520   72.989390   1421.830239    1.408035   \n",
       "std     1722.374379    4.667409   90.803798   3634.398730    0.537000   \n",
       "min        0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "25%      117.000000    4.405405   29.000000    217.000000    1.233333   \n",
       "50%      331.000000    6.627737   54.000000    677.000000    1.468227   \n",
       "75%      854.000000    8.674699   88.000000   1529.000000    1.750000   \n",
       "max    28201.000000   39.500000  994.000000  60190.000000    3.000000   \n",
       "\n",
       "          NBD_max       NBD_sum        NOCU     NOF_avg     NOF_max  \\\n",
       "count  377.000000    377.000000  377.000000  377.000000  377.000000   \n",
       "mean     4.970822    284.503979   17.848806    2.655245   12.607427   \n",
       "std      2.323950    687.157223   22.557750    3.885536   20.484679   \n",
       "min      0.000000      0.000000    1.000000    0.000000    0.000000   \n",
       "25%      4.000000     51.000000    6.000000    1.000000    4.000000   \n",
       "50%      5.000000    143.000000   11.000000    2.076923    8.000000   \n",
       "75%      6.000000    320.000000   22.000000    3.352941   14.000000   \n",
       "max     17.000000  11611.000000  242.000000   63.250000  251.000000   \n",
       "\n",
       "          NOF_sum     NOI_avg     NOI_max     NOI_sum     NOM_avg     NOM_max  \\\n",
       "count  377.000000  377.000000  377.000000  377.000000  377.000000  377.000000   \n",
       "mean    54.798408    0.172434    0.509284    2.822281    7.919620   32.379310   \n",
       "std     94.776931    0.277450    0.500578    6.726633    5.384483   37.169636   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     10.000000    0.000000    0.000000    0.000000    4.842105   13.000000   \n",
       "50%     25.000000    0.019048    1.000000    1.000000    6.780488   22.000000   \n",
       "75%     62.000000    0.214286    1.000000    3.000000    9.500000   40.000000   \n",
       "max    994.000000    1.000000    1.000000   76.000000   42.000000  297.000000   \n",
       "\n",
       "           NOM_sum     NOT_avg     NOT_max     NOT_sum     NSF_avg  \\\n",
       "count   377.000000  377.000000  377.000000  377.000000  377.000000   \n",
       "mean    177.769231    0.827946    0.978780   15.034483    2.277422   \n",
       "std     443.802545    0.277751    0.177379   21.431146    6.283659   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      37.000000    0.785714    1.000000    3.000000    0.383333   \n",
       "50%      83.000000    0.980952    1.000000   10.000000    1.000000   \n",
       "75%     209.000000    1.000000    1.000000   18.000000    2.000000   \n",
       "max    7669.000000    1.111111    2.000000  241.000000   94.333333   \n",
       "\n",
       "           NSF_max      NSF_sum     NSM_avg     NSM_max     NSM_sum  \\\n",
       "count   377.000000   377.000000  377.000000  377.000000  377.000000   \n",
       "mean     21.811671    41.076923    1.181801   12.604775   21.246684   \n",
       "std      72.670226    94.109527    3.402363   51.386834   69.903088   \n",
       "min       0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "25%       2.000000     4.000000    0.037037    1.000000    1.000000   \n",
       "50%       6.000000    12.000000    0.416667    3.000000    6.000000   \n",
       "75%      14.000000    33.000000    1.090909   10.000000   18.000000   \n",
       "max    1049.000000  1119.000000   56.714286  596.000000  938.000000   \n",
       "\n",
       "          PAR_avg     PAR_max      PAR_sum     TLOC_avg     TLOC_max  \\\n",
       "count  377.000000  377.000000   377.000000   377.000000   377.000000   \n",
       "mean     1.020060    4.957560   210.114058   117.645997   494.687003   \n",
       "std      0.439893    3.203771   455.568578   127.328041   593.967554   \n",
       "min      0.000000    0.000000     0.000000     5.800000     6.000000   \n",
       "25%      0.743455    3.000000    44.000000    59.700000   176.000000   \n",
       "50%      0.954220    4.000000   105.000000    97.153846   327.000000   \n",
       "75%      1.173077    6.000000   224.000000   140.000000   595.000000   \n",
       "max      3.000000   28.000000  7059.000000  1872.000000  5207.000000   \n",
       "\n",
       "           TLOC_sum      VG_avg      VG_max        VG_sum  \n",
       "count    377.000000  377.000000  377.000000    377.000000  \n",
       "mean    2113.901857    2.276089   19.809019    480.114058  \n",
       "std     4824.224327    1.327293   29.697421   1343.046313  \n",
       "min        6.000000    0.000000    0.000000      0.000000  \n",
       "25%      421.000000    1.673913    7.000000     71.000000  \n",
       "50%     1080.000000    2.211268   13.000000    228.000000  \n",
       "75%     2305.000000    2.674699   22.000000    535.000000  \n",
       "max    79474.000000   12.460000  310.000000  23255.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    377.000000\n",
       "mean       2.432361\n",
       "std        6.241702\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max       88.000000\n",
       "Name: post, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_np = train_x.to_numpy()\n",
    "test_x_np = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_np = train_y.to_numpy()\n",
    "train_y_np = np.where(train_y_np > 0, 1, 0)\n",
    "test_y_np = test_y.to_numpy()\n",
    "test_y_np = np.where(test_y_np > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training single tree took 1.0782661437988281 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "single_tree = tree_grow(train_x_np, train_y_np, 15, 5, 41)\n",
    "end = time()\n",
    "print(f\"Training single tree took {end-start} seconds\")\n",
    "test_y_np_pred_st = tree_pred(test_x_np, single_tree)\n",
    "preds_model[\"single tree\"] = test_y_np_pred_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(single_tree.y) == (len(single_tree.l.y) + len(single_tree.r.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_scores(y_true,y_pred):\n",
    "    conf_mat = confusion_matrix(y_true,y_pred)\n",
    "    tn = conf_mat[0][0]\n",
    "    fp = conf_mat[0][1]\n",
    "    fn = conf_mat[1][0]\n",
    "    tp = conf_mat[1][1]\n",
    "    print(\"Confusion matrix:\")\n",
    "    display(Markdown(f'''| True/Pred |Pos|Neg|\n",
    "|-----------|---|---|\n",
    "|       Pos |{tp}|{fn}|\n",
    "|       Neg |{fp}|{tn}|\n",
    "    '''))\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"LaTex formatting:\", '''\n",
    "\\\\begin{table}[]\n",
    "\\\\begin{tabular}{|r|l|l|}\n",
    "\\\\hline\n",
    "True/Pred & Pos & Neg \\\\\\ \\hline''')\n",
    "    print(f\"Pos                             &  {tp}   &  {fn}   \\\\\\ \\hline\")\n",
    "    print(f\"Neg                             & {fp}    &  {tn}   \\\\\\ \\hline\")\n",
    "    print('''\\end{tabular}\n",
    "\\end{table}''')\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"accuracy:\", accuracy_score(y_true,y_pred))\n",
    "    print(\"precision:\", precision_score(y_true,y_pred))\n",
    "    print(\"recall:\", recall_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| True/Pred |Pos|Neg|\n",
       "|-----------|---|---|\n",
       "|       Pos |185|128|\n",
       "|       Neg |82|266|\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LaTex formatting: \n",
      "\\begin{table}[]\n",
      "\\begin{tabular}{|r|l|l|}\n",
      "\\hline\n",
      "True/Pred & Pos & Neg \\\\ \\hline\n",
      "Pos                             &  185   &  128   \\\\ \\hline\n",
      "Neg                             & 82    &  266   \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "------------------------------------\n",
      "accuracy: 0.6822995461422088\n",
      "precision: 0.6928838951310862\n",
      "recall: 0.5910543130990416\n"
     ]
    }
   ],
   "source": [
    "report_scores(test_y_np, test_y_np_pred_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root values: split_feature = pre, split_value = 4.5, y_values_1_ratio = 0.5039787798408488\n"
     ]
    }
   ],
   "source": [
    "# Print the first two-layers of the tree\n",
    "# Root node information\n",
    "root = single_tree\n",
    "split_feature = feats[root.f]\n",
    "split_value = root.s\n",
    "y_values = root.y\n",
    "y_values_1_ratio = sum(y_values)/len(y_values)\n",
    "print(f\"Root values: split_feature = {split_feature}, split_value = {split_value}, y_values_1_ratio = {y_values_1_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187 190]\n",
      "4.5\n",
      "pre\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.y))\n",
    "# print(single_tree.f)\n",
    "print(single_tree.s)\n",
    "print(feats[single_tree.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156  58]\n",
      "26.5\n",
      "VG_max\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.l.y))\n",
    "print(single_tree.l.s)\n",
    "print(feats[single_tree.l.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31 132]\n",
      "0.1583333333333333\n",
      "NOI_avg\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.r.y))\n",
    "print(single_tree.r.s)\n",
    "print(feats[single_tree.r.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150  41]\n",
      "54.5\n",
      "NSM_sum\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.l.l.y))\n",
    "print(single_tree.l.l.s)\n",
    "print(feats[single_tree.l.l.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 17]\n",
      "358.0\n",
      "VG_sum\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.l.r.y))\n",
    "print(single_tree.l.r.s)\n",
    "print(feats[single_tree.l.r.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11 107]\n",
      "11.5\n",
      "pre\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.r.l.y))\n",
    "print(single_tree.r.l.s)\n",
    "print(feats[single_tree.r.l.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 25]\n",
      "9.5\n",
      "NOCU\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(single_tree.r.r.y))\n",
    "print(single_tree.r.r.s)\n",
    "print(feats[single_tree.r.r.f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "bagging_tree = tree_grow_b(train_x_np, train_y_np, 15, 5, 41, 100)\n",
    "end = time()\n",
    "print(f\"Training bagging tree took {end-start} seconds\")\n",
    "test_y_np_pred_bt = tree_pred_b(test_x_np, bagging_tree)\n",
    "preds_model[\"bagging tree\"] = test_y_np_pred_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_y_np, test_y_np_pred_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "random_tree = tree_grow_b(train_x_np, train_y_np, 15, 5, 6, 100)\n",
    "end = time()\n",
    "print(f\"Training random forest took {end-start} seconds\")\n",
    "test_y_np_pred_rt = tree_pred_b(test_x_np, random_tree)\n",
    "preds_model[\"random forest\"] = test_y_np_pred_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_scores(test_y_np, test_y_np_pred_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(preds_model.keys())\n",
    "tables = []\n",
    "for model1 in models:\n",
    "    for model2 in models:\n",
    "        if not(model1 == model2):\n",
    "            print(f\"McNemar's test {model1} vs {model2}\")\n",
    "            # The code in the following three lines was adopted from [1].\n",
    "            table = mcnemar_table(y_target=test_y_np, y_model1=preds_model[model1], y_model2=preds_model[model2])\n",
    "            tables.append(table)\n",
    "            chi2_, p = mcnemar(ary=table, corrected=True)\n",
    "            print(f\"chi² statistic: {chi2_}, p-value: {p}\\n\")\n",
    "    models.remove(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables:\n",
    "    print(\"LaTex formatting:\", '''\n",
    "    \\\\begin{table}[]\n",
    "    \\\\begin{tabular}{|r|l|l|}\n",
    "    \\\\hline\n",
    "    Model1/Model2 & Wrong & Right \\\\\\ \\hline''')\n",
    "    print(f\"Wrong                             &  {table[0][0]}   &  {table[0][1]}   \\\\\\ \\hline\")\n",
    "    print(f\"Right                             & {table[1][0]}    &  {table[1][1]}   \\\\\\ \\hline\")\n",
    "    print('''\\end{tabular}\n",
    "    \\end{table}''')\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] T. Toledo Jr, “Statistical tests for comparing classification algorithms,” Medium, Jan. 04, 2022. [Online]. Available: https://towardsdatascience.com/statistical-tests-for-comparing-classification-algorithms-ac1804e79bb7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
